{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.019545Z",
     "start_time": "2021-01-09T03:10:58.001590Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import data as gdata,Trainer\n",
    "import sys\n",
    "import time\n",
    "from mxnet import nd,autograd\n",
    "import d2lzh as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.587374Z",
     "start_time": "2021-01-09T03:10:58.021536Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train len: 60000,\n",
      "mnist_test len:10000\n"
     ]
    }
   ],
   "source": [
    "mnist_train = gdata.vision.FashionMNIST(train=True)\n",
    "mnist_test = gdata.vision.FashionMNIST(train=False)\n",
    "print('mnist_train len: %d,\\nmnist_test len:%d' %\n",
    "      (len(mnist_train), len(mnist_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.602334Z",
     "start_time": "2021-01-09T03:10:58.590365Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_workers():\n",
    "    if sys.platform.startswith('win'):\n",
    "        num_workers = 0\n",
    "    else:\n",
    "        num_workers = 4\n",
    "    return num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.618289Z",
     "start_time": "2021-01-09T03:10:58.605326Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "transformer = gdata.vision.transforms.ToTensor()\n",
    "train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n",
    "                             batch_size=batch_size,shuffle=True,num_workers=get_num_workers())\n",
    "test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),batch_size=batch_size,\n",
    "                            shuffle=False,num_workers=get_num_workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.633278Z",
     "start_time": "2021-01-09T03:10:58.621283Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "input_nums = 784\n",
    "output_nums = 10\n",
    "\n",
    "def softmax(X):\n",
    "    X_exp = X.exp()\n",
    "    partition = X_exp.sum(axis=1,keepdims = True)\n",
    "    return X_exp / partition\n",
    "def net(X):\n",
    "    return softmax(np.dot(X.reshape(-1,input_nums),W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.649207Z",
     "start_time": "2021-01-09T03:10:58.635245Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat,y):\n",
    "    return -np.pick(y_hat,y).log()\n",
    "\n",
    "def accuracy(y_hat,y):\n",
    "   return (y_hat.argmax(axis=1) == y.astype('float32')).mean().asscalar()\n",
    "\n",
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum = 0.0\n",
    "    for X,y in data_iter:\n",
    "        y = y.astype('float32')\n",
    "        y_hat = net(X)\n",
    "        acc_sum += (y_hat.argmax(axis=1) == y).mean().asscalar()#\n",
    "    return acc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.665165Z",
     "start_time": "2021-01-09T03:10:58.651202Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(net,train_iter,test_iter,num_epochs,batch_size,loss,params,lr,trainer):\n",
    "    for epochs in range(num_epochs):\n",
    "        for X,y in train_iter:\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat,y).sum()\n",
    "            l.backward()\n",
    "            \n",
    "            if trainer is None:\n",
    "                d2lzh.sgd(params,lr,batch_size)\n",
    "            else:\n",
    "                trainer.step(batch_size)\n",
    "                \n",
    "            y = y.asstype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n+=y.size\n",
    "        test_acc = evaluate_accuracy(test_iter,net)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.681123Z",
     "start_time": "2021-01-09T03:10:58.668157Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-31-e08b1c27c157>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-e08b1c27c157>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def train(net,train_iter,test_iter,num_epochs,batch_size,loss,trainer,params=None,lr,weight_decay=None):\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def train(net,train_iter,test_iter,num_epochs,batch_size,loss,trainer,params=None,lr,weight_decay=None):\n",
    "    acc_sum,l_sum,n = 0.0,0.0,0\n",
    "    for epoch in range(num_epochs):\n",
    "        for X,y in train_iter:\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat,y)\n",
    "            l.backward()\n",
    "            \n",
    "            if trainer is None:\n",
    "                d2l.sgd(params,lr,batch_size)\n",
    "            else:\n",
    "                trainer.step(batch_size)\n",
    "                \n",
    "            l_sum += l.asscalar()\n",
    "            acc_sum += (y_hat.argmax(axis=1) == y.astype('float32')).sum.asscalar()\n",
    "            n+=y.size\n",
    "        test_acc = evaluate_accuracy(test_iter,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T03:10:58.683118Z",
     "start_time": "2021-01-09T03:10:58.017Z"
    }
   },
   "outputs": [],
   "source": [
    "for X,y in test_iter:\n",
    "    break\n",
    "true_labels = d2l.get_fashion_mnist_labels(y.asnumpy())\n",
    "pred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1).asnumpy())\n",
    "title = [true + '\\n' + pred for true,pred in zip(true_labels,pred_labels)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jn_mxnet",
   "language": "python",
   "name": "mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 692,
   "position": {
    "height": "744px",
    "left": "1288px",
    "right": "20px",
    "top": "145px",
    "width": "341px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
