{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import autograd,gluon,init,nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 批量归一化Batch Normalization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def batch_norm(X,gamma,beta,moving_mean,moving_var,eps,momentum):\n",
    "    # 通过autograd判断当前是训练模式还是预测模式\n",
    "    if not autograd.is_training(): #  如果不是在训练，那就直接用成果。\n",
    "        # 直接使用传入的移动平均所得的均值和方差.moving_var是方差！！\n",
    "        X_hat = (X - moving_mean) / nd.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2,4)\n",
    "        # 根据形状来生成mean & var\n",
    "        if len(X.shape) == 2: # 即输出的是一个矩阵。因为有batch！！！每一个batch一行\n",
    "            # 使用全连层的情况，计算特征维上的均值 & 方差\n",
    "            mean = X.mean(axis=0) # 统计每一行的平均值\n",
    "            var = ((X - mean) ** 2).mean(axis=0) # 平均方差\n",
    "        else: # 使用二维卷积的情况下，计算每个通道（axis=1)的均值&方差。\n",
    "            # 这里我们需要保持X的形状以便后面可以做广播运算\n",
    "            mean = X.mean(axis=(0,2,3),keepdims=True) # 注意是每个通道一组参数！！不是每个批次一组。参数公用是横着来！！\n",
    "            var = ((X - mean) ** 2).mean(axis=(0,2,3),keepdims=True)\n",
    "    \n",
    "        # 训练模式下用当前的均值&方差做标准化\n",
    "        X_hat = (X-mean) / nd.sqrt(var + eps)\n",
    "\n",
    "        # 更新移动平均的均值&方差\n",
    "        moving_mean = momentum * moving_mean + (1.0-momentum)*mean # 动量法！！！\n",
    "        moving_var = momentum * moving_var + (1.0-momentum)*var\n",
    "    \n",
    "    Y = gamma * X_hat + beta # 拉伸和偏移\n",
    "    return Y ,moving_mean,moving_var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchNorm层\n",
    "---\n",
    "- 参与求梯度的参数\n",
    "    1. 拉伸参数gamma\n",
    "    2. 偏移参数beta\n",
    "- 维护：移动平均得到的\n",
    "    1. 均值moving_mean\n",
    "    2. 方差moving_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Block):\n",
    "    # 一般init都是初始化一些变量而已~\n",
    "    def __init__(self,num_features,num_dims,**kwargs):\n",
    "        super(BatchNorm,self).__init__(**kwargs)\n",
    "        # 如果左边是个全连层\n",
    "        if num_dims == 2:\n",
    "            shape = (1,num_features)\n",
    "        else:\n",
    "            shape = (1,num_features,1,1)\n",
    "            \n",
    "        # 参与求梯度和迭代的 【拉伸】&【偏移】参数，分别初始化成1、0\n",
    "        self.gamma = self.params.get('gamma',shape = shape,init=init.One())\n",
    "        self.beta = self.params.get('beta',shape = shape,init=init.Zero())\n",
    "        \n",
    "        # 不参与求梯度和迭代的变量，全在内存上初始化为0\n",
    "        self.moving_mean = nd.zeros(shape)\n",
    "        self.moving_var = nd.zeros(shape)\n",
    "        \n",
    "    # forward一般都是在计算变量\n",
    "    def forward(self,X):\n",
    "        # 如果X不在内存上，将moving_mean & moving_var复制到显存上\n",
    "        if self.moving_mean.context != X.context:\n",
    "            self.moving_mean = self.moving_mean.copyto(X.context)\n",
    "            self.moving_var = self.moving_var.copyto(X.context)\n",
    "        \n",
    "        # 保存更新过的moving_mean & moving_var\n",
    "        Y,self.moving_mean,self.moving_varv = batch_norm(X,self.gamma.data(),self.beta.data(),\n",
    "                                                         self.moving_mean,self.moving_var,\n",
    "                                                         eps = 1e-5,momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jn_mxnet",
   "language": "python",
   "name": "mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
