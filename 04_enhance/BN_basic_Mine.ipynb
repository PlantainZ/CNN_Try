{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import autograd,gluon,init,nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X,gamma,beta,moving_mean,moving_var,eps,momentum):\n",
    "    if  not autograd.is_training():\n",
    "        X_hat = (X-moving_mean) / nd.sqrt(moving_var + aps)\n",
    "    else: \n",
    "        assert len(X.shape) in (2,4)    \n",
    "        if len(X.shape)==2:\n",
    "            mean = X.mean(axis=0)\n",
    "            var = ((X-mean)**2).mean(axis=0)\n",
    "        else: \n",
    "            mean = X.mean(axis=(0,2,3),keepdims=True)\n",
    "            var = ((X-mean)**2).mean(axis=(0,2,3),keepdims=True)\n",
    "            \n",
    "        X_hat = (X-mean) / nd.sqrt(var + eps)\n",
    "\n",
    "        moving_mean = momentum * moving_mean + (1.0-momentum)*mean # 动量法！！！\n",
    "        moving_var = momentum * moving_var + (1.0-momentum)*var\n",
    "        \n",
    "    Y = gamma*y_hat + beta\n",
    "    return Y,moving_mean,moving_var\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Block):\n",
    "    def __init__(self,num_features,num_dims,**kwargs):\n",
    "        super(BatchNorm,self).__init__(**kwargs)\n",
    "        \n",
    "        if num_dims == 2 :\n",
    "            shape = (1,num_features)\n",
    "        else:\n",
    "            shape = (1,num_features,1,1)\n",
    "        \n",
    "        self.gamma = self.params.get('gamma',shape = shape,init=init.One())\n",
    "        self.beta = self.params.get('beta',shape = shape,init=init.Zero())\n",
    "            \n",
    "        self.moving_mean = nd.zeros(shape)\n",
    "        self.moving_var = nd.zeros(shape)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        if self.moving_mean.context != X.context:\n",
    "            self.moving_mean = self.moving_mean.copyto(X.context)\n",
    "            self.moving_varv = self.moving_var.copyto(X.context)\n",
    "        \n",
    "        Y,self.moving_mean,self.moving_var = batch_norm(X,self.gamma.data(),self.beta.data(),\n",
    "                                                       self.moving_mean,self.moving_var,\n",
    "                                                       eps=1e-5,momentum=0.9)\n",
    "        return Y "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jn_mxnet",
   "language": "python",
   "name": "mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
