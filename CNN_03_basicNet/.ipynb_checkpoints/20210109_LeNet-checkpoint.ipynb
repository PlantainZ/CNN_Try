{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "import mxnet as mx\n",
    "from mxnet import autograd,gluon,init,nd\n",
    "from mxnet.gluon import loss as gloss,nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nd.random.normal(shape=(1,1,28,28))\n",
    "\n",
    "batch_size = 256\n",
    "train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意！！用的全是sigmoid\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=6,kernel_size=5,activation='sigmoid'),\n",
    "        nn.MaxPool2D(pool_size=2,strides=2),\n",
    "        nn.Conv2D(channels=16,kernel_size=5,activation='sigmoid'),\n",
    "        nn.MaxPool2D(pool_size=2,strides=2),\n",
    "\n",
    "        nn.Dense(120,activation='sigmoid'),\n",
    "        nn.Dense(84,activation='sigmoid'),\n",
    "        nn.Dense(10))\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0 output shape:\t (1, 6, 24, 24)\n",
      "pool0 output shape:\t (1, 6, 12, 12)\n",
      "conv1 output shape:\t (1, 16, 8, 8)\n",
      "pool1 output shape:\t (1, 16, 4, 4)\n",
      "dense0 output shape:\t (1, 120)\n",
      "dense1 output shape:\t (1, 84)\n",
      "dense2 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "for layer in net:# 可以这样看output信息！！！\n",
    "    X=layer(X)\n",
    "    print(layer.name,'output shape:\\t',X.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu(0)\n"
     ]
    }
   ],
   "source": [
    "# 2 # 判断有没有gpu可以用！！=====================================================\n",
    "def try_gpu():\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.zeros((1,),ctx=ctx) # 测试一下这个cpu是否可用，\n",
    "    except mx.base.MXNetError:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "\n",
    "ctx = try_gpu()\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 # 开始操作 ==================================================================\n",
    "\n",
    "def evaluate_accuracy(data_iter,net,ctx):\n",
    "    acc_sum,n = nd.array([0],ctx=ctx),0\n",
    "    for X,y in data_iter:\n",
    "        # 如果ctx代表GPU及相应显存，将数据复制到显存上。、记得这个操作！！\n",
    "        X,y = X.as_in_context(ctx),y.as_in_context(ctx).astype('float32')\n",
    "        acc_sum = (net(X).argmax(axis=1) == y).sum() # argmax在mxnet中会返回浮点数\n",
    "        n+=y.size\n",
    "    return acc_sum.asscalar()/n # 这里转成标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LeNet(train_iter,test_iter,net,\n",
    "              batch_size,num_epochs,trainer,ctx):\n",
    "    print('training on',ctx)\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,start= 0.0,0.0,0,time.time()\n",
    "        for X,y in train_iter:\n",
    "            X,y = X.as_in_context(ctx),y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat,y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "\n",
    "            # 都转化成标量！！\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum = l.asscalar()\n",
    "            train_acc_sum = (y_hat.argmax(axis =1 ) ==y).sum().asscalar()\n",
    "            n+=y.size\n",
    "        test_acc = evaluate_accuracy(test_iter,net,ctx) # 每个epochs完之后都要计算下模型的正确率\n",
    "        print('epoch %d,loss %.3f,train_acc %.4f,test_acc %.4f,time: %.1f sec'\n",
    "              %(epoch+1,train_l_sum/n,train_acc_sum/n,test_acc,time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu(0)\n",
      "epoch 1,loss 0.004,train_acc 0.0002,test_acc 0.0003,time: 326.9 sec\n",
      "epoch 2,loss 0.004,train_acc 0.0002,test_acc 0.0001,time: 325.6 sec\n",
      "epoch 3,loss 0.004,train_acc 0.0002,test_acc 0.0003,time: 332.4 sec\n",
      "epoch 4,loss 0.004,train_acc 0.0002,test_acc 0.0001,time: 328.5 sec\n",
      "epoch 5,loss 0.004,train_acc 0.0001,test_acc 0.0003,time: 330.2 sec\n"
     ]
    }
   ],
   "source": [
    "# 4 # 走你！===============================================================\n",
    "lr,epoch = 0.1,5\n",
    "\n",
    "# force_reinit : Whether to force re-initialization if parameter is already initialized.是否重加载参数\n",
    "# init : Global default Initializer to be used when Parameter.init() is None. \n",
    "#         Otherwise, Parameter.init() takes precedence.\n",
    "net.initialize(force_reinit=True,ctx=ctx,init=init.Xavier())\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':lr})\n",
    "train_LeNet(train_iter,test_iter,net,batch_size,epoch,trainer,ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jn_mxnet",
   "language": "python",
   "name": "mxnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "583px",
    "left": "1589px",
    "right": "20px",
    "top": "5px",
    "width": "309px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
